{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MittalMonika/Signdetection/blob/main/Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hny4I-ODTIS6"
      },
      "source": [
        "# Simplifying Financial Document Summarization with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nLS57E2TO5y"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Text summarization simplifies lengthy texts into brief, informative summaries. This NLP technique is ideal for condensing news articles, research papers, and other texts.\n",
        "\n",
        "This guide focuses on summarizing financial documents, particularly identifying due taxes and critical deadlines. Summarizing financial texts involves extracting key dates, tax obligations, and preparatory steps required before deadlines. Prior familiarity with basic summarization techniques is advantageous for effectively handling complex financial documents.\n",
        "\n",
        "Utilize LangChain in this Google Colab notebook to apply advanced summarization strategies specifically tailored for financial documents. Through practical examples, you'll learn to efficiently extract essential information, ensuring timely tax submissions and compliance with financial deadlines.\n",
        "\n",
        "[Blog](https://medium.com/google-cloud/langchain-chain-types-large-document-summarization-using-langchain-and-google-cloud-vertex-ai-1650801899f6related)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXsvgIuwTPZw"
      },
      "source": [
        "### Objective\n",
        "\n",
        " To summarize large finacial documents there are different LLM methods and API but I am exploring OpenAI, and further Vertex AI Generative AI Studio of Google Cloud can be explored and following methods:\n",
        "\n",
        "- Stuffing method\n",
        "- MapReduce method\n",
        "- Refine method"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "open_api_key=\"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\"\n",
        "os.environ[\"OPENAI_API_KEY\"]=open_api_key"
      ],
      "metadata": {
        "id": "BPlwteVDKFLL"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aP6JVlZkS-m"
      },
      "outputs": [],
      "source": [
        "!sudo apt -y -qq install tesseract-ocr\n",
        "!sudo apt -y -qq install libtesseract-dev\n",
        "!sudo apt-get -y -qq install poppler-utils #required by PyPDF2 for page count and other pdf utilities\n",
        "!sudo apt-get -y -qq install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install  pytesseract pypdf  PyPDF2 textract langchain transformers openai tiktoken"
      ],
      "metadata": {
        "id": "wzrS_SQcR0Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cRkcfnQMT9vD"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "import warnings\n",
        "from pathlib import Path as p\n",
        "\n",
        "import pandas as pd\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.llms import VertexAI\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZkLDRTjTcfm"
      },
      "source": [
        "### Preparing data files\n",
        "\n",
        "To begin, you will need to download a few files that are required for the summarizing tasks below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7H0zINHpTaSu"
      },
      "outputs": [],
      "source": [
        "data_folder = p.cwd() / \"data\"\n",
        "p(data_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#pdf_url = \"https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf\"\n",
        "pdf_file = str(p(data_folder, 'tax1.pdf'))\n",
        "\n",
        "#urllib.request.urlretrieve(pdf_url, pdf_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JELITHdBhnf0"
      },
      "source": [
        "### Extract text from the PDF\n",
        "\n",
        "You use an `PdfReader` to extract the text from our scanned documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "x3INtovxreI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46efddaa-d4b7-46ae-ba95-98ca35c6d5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notice of Balance Due for Tax Year 2018 Notice Date: May 6, 2019 Social Security Number: XXX-KX-X0K To contact us: 800-829-1040 Your Caller ID: OOK Page 1 of 4You have a balance due for 2018Amount due: $262.76Our records show you have unpaid taxes and/or penalties and interest on your December 31, 2018 Form 1040. If you already have an installment or payment agreement in place for this tax year, then continue with that agreement.Billing Summary: Tax you owed: $38,371.00 Payments and credits: $0.00 Failure to pay proper estimated tax penalty: $262.76 Amount due by May 27, 2019: $262.76\n"
          ]
        }
      ],
      "source": [
        "pdf_loader = PyPDFLoader(pdf_file)\n",
        "pages = pdf_loader.load_and_split()\n",
        "text = pages[0].page_content\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "three_pages = pages[:1]"
      ],
      "metadata": {
        "id": "R5QjmYoRU3gX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDVwBFSjZ7ws"
      },
      "source": [
        "## Method 1: Stuffing\n",
        "\n",
        "Stuffing is the simplest method to pass data to a language model. It \"stuffs\" text into the prompt as context in a way that all of the relevant information can be processed by the model to get what you want.\n",
        "\n",
        "In LangChain, you can use `StuffDocumentsChain` as part of the `load_summarize_chain` method. What you need to do is setting `stuff` as `chain_type` of your chain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhEi-XqKnv2v"
      },
      "source": [
        "### Prompt design with `Stuffing` chain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Basic Prompt Summarization\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import(\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ],
      "metadata": {
        "id": "G8R7UUTpKifl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_messages=[\n",
        "    SystemMessage(content='You are an expert assistant with expertize in summarizing financial documents extracting the tax to be paid and date'),\n",
        "    HumanMessage(content=f'Please provide a short and concise summary of the following speech:\\n TEXT: {three_pages}')\n",
        "]\n",
        "\n",
        "llm=ChatOpenAI(model_name='gpt-3.5-turbo')"
      ],
      "metadata": {
        "id": "sI5XPFZPUg-Y"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.get_num_tokens(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnB-xCbxVwnj",
        "outputId": "a6d23d5e-e89f-47d8-ea4c-543f29d88a07"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "183"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "B-ljajUen1YO"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"Write a concise summary of the following text delimited by triple backquotes.\n",
        "              Return your response in bullet points which covers the key points of the text.\n",
        "              ```{text}```\n",
        "              BULLET POINT SUMMARY:\n",
        "  \"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
      ],
      "metadata": {
        "id": "LsMHRC5nZojz"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.docstore.document import Document"
      ],
      "metadata": {
        "id": "DgrzxLb7Z5H5"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = '''Write a concise and short summary of the following financial document Response your answer with the information a line about the form or motive and then provide 1. Name or SSN of the person , 2. tax to be paid, 3.date by it should be paid.\n",
        "Speech: `{text}`\n",
        "'''\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=['text'],\n",
        "    template=template\n",
        ")"
      ],
      "metadata": {
        "id": "MTGFyVbzaIrv"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_summarize_chain(\n",
        "    llm,\n",
        "    chain_type='stuff',\n",
        "    prompt=prompt,\n",
        "    verbose=False\n",
        ")\n",
        "output_summary = chain.run(three_pages)"
      ],
      "metadata": {
        "id": "4o0b4qZ4aKOI"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the output into lines\n",
        "lines = output_summary.split('\\n')\n",
        "\n",
        "# Parsing each line to extract information\n",
        "summary_data = {}\n",
        "for line in lines:\n",
        "    # Splitting each line by the first occurrence of \": \"\n",
        "    key, value = line.split(': ', 1)\n",
        "    summary_data[key] = value\n",
        "\n",
        "# Now, `summary_data` is a dictionary with the extracted data\n",
        "print(summary_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DMCuEGInB3J",
        "outputId": "99bc9353-d54e-4923-a156-1b1e873be06e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Form/Motive': 'Notice of Balance Due for Tax Year 2018', '1. Name or SSN of the person': 'XXX-KX-X0K', '2. Tax to be paid': '$262.76', '3. Date by which it should be paid': 'May 27, 2019'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nZ7dbZqnmqAW",
        "outputId": "dd4eab1f-d5c2-4629-a7ff-5a2a677c07b1"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Name or SSN of the person: XXX-KX-X0K\\nTax to be paid: $262.76\\nDate by which it should be paid: May 27, 2019'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TfG1pj43mV9h",
        "outputId": "75833743-7435-4a3a-beac-3b40662b15c6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. Name of the person: Not provided\\n2. Tax to be paid: $262.76\\n3. Date by which it should be paid: May 27, 2019'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "ccEuH2BBmC4e",
        "outputId": "8abd7f8a-ab1f-4a83-c7a7-0894832c7b80"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'- Notice of Balance Due for Tax Year 2018\\n- Notice Date: May 6, 2019\\n- Social Security Number: XXX-KX-X0K\\n- Contact number: 800-829-1040\\n- Caller ID: OOK\\n- Balance due for 2018: $262.76\\n- Unpaid taxes and/or penalties and interest on December 31, 2018 Form 1040\\n- If installment or payment agreement is in place, continue with that agreement\\n- Billing Summary:\\n  - Tax owed: $38,371.00\\n  - Payments and credits: $0.00\\n  - Failure to pay proper estimated tax penalty: $262.76\\n- Amount due by May 27, 2019: $262.76'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "N8B524nMljmP",
        "outputId": "21793508-7e15-412d-c1dc-f3159aa1fed6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Summary: The document is a notice of balance due for tax year 2018. The recipient has a balance due of $262.76, which includes unpaid taxes, penalties, and interest. The amount is to be paid by May 27, 2019.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "cXUiIju_d-9-",
        "outputId": "a44ddf1b-b0a3-4165-c5dd-243cbf483532"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This speech is a notice informing the recipient that they have a balance due for the tax year 2018. The amount due is $262.76, which includes unpaid taxes, penalties, and interest. The recipient is advised to continue with any existing installment or payment agreement. The deadline for payment is May 27, 2019.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5aVrDWkJs3Y"
      },
      "source": [
        "### Retrying\n",
        "Initiate a chain using `stuff` method and process three pages document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKb_fBEedZqu"
      },
      "source": [
        " With the `stuff` method, you can summarize the entire document content with a single API call passing all data at once.\n",
        "\n",
        "Depending on the context length of LLM, the `stuff` method would not work as it result in a prompt larger than the context length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtp21WX3T7d_"
      },
      "source": [
        "As expected, the code returns the expection message."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqZrKM32h-o2"
      },
      "source": [
        "### Considerations\n",
        "\n",
        "The `stuffing` method is a way to summarize text by feeding the entire document to a large language model (LLM) in a single call. This method has both pros and cons.\n",
        "\n",
        "The stuffing method only requires a single call to the LLM, which can be faster than other methods that require multiple calls. When summarizing text, the LLM has access to all the data at once, which can result in a better summary.\n",
        "\n",
        "But, LLMs have a context length, which is the maximum number of tokens that can be processed in a single call. If the document is longer than the context length, the stuffing method will not work. Also the stuffing method is not suitable for summarizing large documents, as it can be slow and may not produce a good summary.\n",
        "\n",
        "Let's explore other approaches to help deal with having longer text than context lengh limit of LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM3V1JARZ9-k"
      },
      "source": [
        "## Method 2: MapReduce\n",
        "\n",
        "The `MapReduce` method implements a multi-stage summarization. It is a technique for summarizing large pieces of text by first summarizing smaller chunks of text and then combining those summaries into a single summary.\n",
        "\n",
        "In LangChain, you can use `MapReduceDocumentsChain` as part of the `load_summarize_chain` method. What you need to do is setting `map_reduce` as `chain_type` of your chain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lagLXEamlPY2"
      },
      "source": [
        "### Prompt design with `MapReduce` chain\n",
        "\n",
        "In our example, you have a 32-page document that you need to summarize.\n",
        "\n",
        "With LangChain, the `map_reduce` chain breaks the document down into 1024 token chunks max. Then it runs the initial prompt you define on each chunk to generate a summary of that chunk. In the example below, you use the following first stage or map prompt.\n",
        "\n",
        "```Write a concise summary of the following text delimited by triple backquotes. Return your response in bullet points which covers the key points of the text.\n",
        "'''{text}'''. BULLET POINT SUMMARY:```\n",
        "\n",
        "Once summaries for all of the chunks are generated, it runs a different prompt to combine those summaries into a single summary. In the example below, you use the following second stage or combine prompt.\n",
        "\n",
        "```Write a summary of the entire document that includes the main points from all of the individual summaries.```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6oHEtdSmsTn"
      },
      "outputs": [],
      "source": [
        "map_prompt_template = \"\"\"\n",
        "                      Write a summary of this chunk of text that includes the main points and any important details.\n",
        "                      {text}\n",
        "                      \"\"\"\n",
        "\n",
        "map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
        "\n",
        "combine_prompt_template = \"\"\"\n",
        "                      Write a concise summary of the following text delimited by triple backquotes.\n",
        "                      Return your response in bullet points which covers the key points of the text.\n",
        "                      ```{text}```\n",
        "                      BULLET POINT SUMMARY:\n",
        "                      \"\"\"\n",
        "\n",
        "combine_prompt = PromptTemplate(\n",
        "    template=combine_prompt_template, input_variables=[\"text\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXoz0uLDMoWD"
      },
      "source": [
        "### Generate summaries using MapReduce method\n",
        "\n",
        "After defining prompts, you initialize the associated `map_reduce_chain`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRGJcBZeVdEa"
      },
      "outputs": [],
      "source": [
        "map_reduce_chain = load_summarize_chain(\n",
        "    vertex_llm_text,\n",
        "    chain_type=\"map_reduce\",\n",
        "    map_prompt=map_prompt,\n",
        "    combine_prompt=combine_prompt,\n",
        "    return_intermediate_steps=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6fekDDr0hrJ"
      },
      "source": [
        "Then, you generate summaries using the chain. Notice that LangChain use a tokenizer (from transformer library) with 1024 token limit by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSC6w2TBV35q"
      },
      "outputs": [],
      "source": [
        "map_reduce_outputs = map_reduce_chain({\"input_documents\": pages})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meH2ELuz2H46"
      },
      "source": [
        "After summaries are generated, you can validate them by organize input documents and associated output in a Pandas Dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6FRSR7xRLew"
      },
      "outputs": [],
      "source": [
        "final_mp_data = []\n",
        "for doc, out in zip(\n",
        "    map_reduce_outputs[\"input_documents\"], map_reduce_outputs[\"intermediate_steps\"]\n",
        "):\n",
        "    output = {}\n",
        "    output[\"file_name\"] = p(doc.metadata[\"source\"]).stem\n",
        "    output[\"file_type\"] = p(doc.metadata[\"source\"]).suffix\n",
        "    output[\"page_number\"] = doc.metadata[\"page\"]\n",
        "    output[\"chunks\"] = doc.page_content\n",
        "    output[\"concise_summary\"] = out\n",
        "    final_mp_data.append(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA9cnh8YaNbF"
      },
      "outputs": [],
      "source": [
        "pdf_mp_summary = pd.DataFrame.from_dict(final_mp_data)\n",
        "pdf_mp_summary = pdf_mp_summary.sort_values(\n",
        "    by=[\"file_name\", \"page_number\"]\n",
        ")  # sorting the dataframe by filename and page_number\n",
        "pdf_mp_summary.reset_index(inplace=True, drop=True)\n",
        "pdf_mp_summary.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA0eM1K3cvH2"
      },
      "outputs": [],
      "source": [
        "index = 3\n",
        "print(\"[Context]\")\n",
        "print(pdf_mp_summary[\"chunks\"].iloc[index])\n",
        "print(\"\\n\\n [Simple Summary]\")\n",
        "print(pdf_mp_summary[\"concise_summary\"].iloc[index])\n",
        "print(\"\\n\\n [Page number]\")\n",
        "print(pdf_mp_summary[\"page_number\"].iloc[index])\n",
        "print(\"\\n\\n [Source: file_name]\")\n",
        "print(pdf_mp_summary[\"file_name\"].iloc[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROrE1-HKpg7y"
      },
      "source": [
        "### Considerations\n",
        "\n",
        "With `MapReduce` method, the model is able to summarize a large paper by overcoming the context limit of `Stuffing` method with parallel processing.\n",
        "\n",
        "However, the `MapReduce` requires multiple calls to the model and potentially losing context between pages.\n",
        "\n",
        "To deal this challenge, you can try another method to summarize multiple pages at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxdB-5PqgCf-"
      },
      "source": [
        "## Method 3: Refine\n",
        "\n",
        "The Refine method is an alternative method to deal with large document summarization. It works by first running an initial prompt on a small chunk of data, generating some output. Then, for each subsequent document, the output from the previous document is passed in along with the new document, and the LLM is asked to refine the output based on the new document.\n",
        "\n",
        "In LangChain, you can use `MapReduceDocumentsChain` as part of the load_summarize_chain method. What you need to do is setting `refine` as `chain_type` of your chain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjj2UZilDF4Q"
      },
      "source": [
        "### Prompt design with `Refine` chain\n",
        "\n",
        "With LangChain, the `refine` chain requires two prompts.\n",
        "\n",
        "The question prompt to generate the output for subsequent task. The refine prompt to refine the output based on the generated content.\n",
        "\n",
        "In this example, the question prompt is:\n",
        "\n",
        "```\n",
        "Please provide a summary of the following text.\n",
        "TEXT: {text}\n",
        "SUMMARY:\n",
        "```\n",
        "\n",
        "and the refine prompt is:\n",
        "\n",
        "```\n",
        "Write a concise summary of the following text delimited by triple backquotes.\n",
        "Return your response in bullet points which covers the key points of the text.\n",
        "```{text}```\n",
        "BULLET POINT SUMMARY:\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiZX45Z5VTwS"
      },
      "outputs": [],
      "source": [
        "question_prompt_template = \"\"\"\n",
        "                  Please provide a summary of the following text.\n",
        "                  TEXT: {text}\n",
        "                  SUMMARY:\n",
        "                  \"\"\"\n",
        "\n",
        "question_prompt = PromptTemplate(\n",
        "    template=question_prompt_template, input_variables=[\"text\"]\n",
        ")\n",
        "\n",
        "refine_prompt_template = \"\"\"\n",
        "              Write a concise summary of the following text delimited by triple backquotes.\n",
        "              Return your response in bullet points which covers the key points of the text.\n",
        "              ```{text}```\n",
        "              BULLET POINT SUMMARY:\n",
        "              \"\"\"\n",
        "\n",
        "refine_prompt = PromptTemplate(\n",
        "    template=refine_prompt_template, input_variables=[\"text\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-USlaSPbM0rs"
      },
      "source": [
        "### Generate summaries using Refine method\n",
        "\n",
        "After you define prompts, you initiate a summarization chain using `refine` chain type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-Sv3HO1U3hi"
      },
      "outputs": [],
      "source": [
        "refine_chain = load_summarize_chain(\n",
        "    vertex_llm_text,\n",
        "    chain_type=\"refine\",\n",
        "    question_prompt=question_prompt,\n",
        "    refine_prompt=refine_prompt,\n",
        "    return_intermediate_steps=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9EZCDK-MQJH"
      },
      "source": [
        "Then, you use the summatization chain to summarize document using Refine method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHwwab7vXNa1"
      },
      "outputs": [],
      "source": [
        "refine_outputs = refine_chain({\"input_documents\": pages})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUqpki5EMYEr"
      },
      "source": [
        "Below you can see the resulting summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7j5cUGStZ5WF"
      },
      "outputs": [],
      "source": [
        "final_refine_data = []\n",
        "for doc, out in zip(\n",
        "    refine_outputs[\"input_documents\"], refine_outputs[\"intermediate_steps\"]\n",
        "):\n",
        "    output = {}\n",
        "    output[\"file_name\"] = p(doc.metadata[\"source\"]).stem\n",
        "    output[\"file_type\"] = p(doc.metadata[\"source\"]).suffix\n",
        "    output[\"page_number\"] = doc.metadata[\"page\"]\n",
        "    output[\"chunks\"] = doc.page_content\n",
        "    output[\"concise_summary\"] = out\n",
        "    final_refine_data.append(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_7Mm9cEmGOV"
      },
      "outputs": [],
      "source": [
        "pdf_refine_summary = pd.DataFrame.from_dict(final_refine_data)\n",
        "pdf_refine_summary = pdf_mp_summary.sort_values(\n",
        "    by=[\"file_name\", \"page_number\"]\n",
        ")  # sorting the datafram by filename and page_number\n",
        "pdf_refine_summary.reset_index(inplace=True, drop=True)\n",
        "pdf_refine_summary.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvLVCs8Gbwbw"
      },
      "outputs": [],
      "source": [
        "index = 3\n",
        "print(\"[Context]\")\n",
        "print(pdf_refine_summary[\"chunks\"].iloc[index])\n",
        "print(\"\\n\\n [Simple Summary]\")\n",
        "print(pdf_refine_summary[\"concise_summary\"].iloc[index])\n",
        "print(\"\\n\\n [Page number]\")\n",
        "print(pdf_refine_summary[\"page_number\"].iloc[index])\n",
        "print(\"\\n\\n [Source: file_name]\")\n",
        "print(pdf_refine_summary[\"file_name\"].iloc[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dwgbRTrM5Cb"
      },
      "source": [
        "### Considerations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H0Y5pPcXbgm"
      },
      "source": [
        "In short, the Refine method for text summarization with LLMs can pull in more relevant context and may be less lossy than Map Reduce. However, it requires many more calls to the LLM than Stuffing, and these calls are not independent, meaning they cannot be parallelized. Additionally, there is some potential dependency on the ordering of the documents. Latest documents they might become more relevant as this method suffers from recency bias."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-11.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}